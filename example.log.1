DEBUG main org.qcri.rheem.core.optimizer.enumeration.LatentOperatorPruningStrategy - (0:00:05.842 .. 0:00:07.856, p=9.03%) < (0:00:05.868 .. 0:00:07.672, p=9.03%): Choosing [JavaLocalCallbackSink[collect()], SparkFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets], JavaReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets], JavaFilter[my.udf.Sindy.filter1-Filter empty candidate sets], SparkReduceBy[my.udf.Sindy.reduceBy1-Merge cells], SparkTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], JavaMap[Prepare cell merging], SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], JavaUnionAll[2->1, id=60fa3495]] over [JavaLocalCallbackSink[collect()], SparkFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets], SparkMap[Prepare cell merging], JavaReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets], JavaFilter[my.udf.Sindy.filter1-Filter empty candidate sets], SparkReduceBy[my.udf.Sindy.reduceBy1-Merge cells], SparkTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], SparkUnionAll[2->1, id=2cf92cc7]].
DEBUG main org.qcri.rheem.core.optimizer.enumeration.LatentOperatorPruningStrategy - (0:00:05.842 .. 0:00:07.856, p=9.03%) < (0:00:05.953 .. 0:00:08.518, p=9.03%): Choosing [JavaLocalCallbackSink[collect()], SparkFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets], JavaReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets], JavaFilter[my.udf.Sindy.filter1-Filter empty candidate sets], SparkReduceBy[my.udf.Sindy.reduceBy1-Merge cells], SparkTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], JavaMap[Prepare cell merging], SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], JavaUnionAll[2->1, id=60fa3495]] over [JavaLocalCallbackSink[collect()], JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], JavaReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets], JavaFilter[my.udf.Sindy.filter1-Filter empty candidate sets], JavaFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets], SparkTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], JavaMap[Prepare cell merging], JavaReduceBy[my.udf.Sindy.reduceBy1-Merge cells], JavaUnionAll[2->1, id=60fa3495]].
DEBUG main org.qcri.rheem.core.optimizer.enumeration.LatentOperatorPruningStrategy - (0:00:05.842 .. 0:00:07.856, p=9.03%) < (0:00:05.910 .. 0:00:08.059, p=9.03%): Choosing [JavaLocalCallbackSink[collect()], SparkFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets], JavaReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets], JavaFilter[my.udf.Sindy.filter1-Filter empty candidate sets], SparkReduceBy[my.udf.Sindy.reduceBy1-Merge cells], SparkTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], JavaMap[Prepare cell merging], SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], JavaUnionAll[2->1, id=60fa3495]] over [JavaLocalCallbackSink[collect()], SparkFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets], JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], JavaReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets], JavaFilter[my.udf.Sindy.filter1-Filter empty candidate sets], SparkReduceBy[my.udf.Sindy.reduceBy1-Merge cells], JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], JavaMap[Prepare cell merging], JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], JavaUnionAll[2->1, id=60fa3495]].
DEBUG main org.qcri.rheem.core.optimizer.enumeration.LatentOperatorPruningStrategy - (0:00:05.842 .. 0:00:07.856, p=9.03%) < (0:00:05.835 .. 0:00:07.976, p=9.03%): Choosing [JavaLocalCallbackSink[collect()], SparkFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets], JavaReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets], JavaFilter[my.udf.Sindy.filter1-Filter empty candidate sets], SparkReduceBy[my.udf.Sindy.reduceBy1-Merge cells], SparkTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], JavaMap[Prepare cell merging], SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], JavaUnionAll[2->1, id=60fa3495]] over [JavaLocalCallbackSink[collect()], SparkFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets], JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], JavaReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets], JavaFilter[my.udf.Sindy.filter1-Filter empty candidate sets], SparkReduceBy[my.udf.Sindy.reduceBy1-Merge cells], SparkTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], JavaMap[Prepare cell merging], JavaUnionAll[2->1, id=60fa3495]].
DEBUG main org.qcri.rheem.core.optimizer.enumeration.PlanEnumerator - Pruned plan enumeration from 24 to 4 implementations.
DEBUG main org.qcri.rheem.core.optimizer.enumeration.PlanEnumerator - Execute ConcatenationActivator[out@Alternative[3x ~Alternative[[TextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl]]], 545de5a4]: PlanEnumeration[2x, inputs=[], outputs=[out@Alternative[3x ~Alternative[[TextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl]]], 545de5a4]]] -> [PlanEnumeration[4x, inputs=[in@Alternative[3x ~Alternative[[FlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl]]], 4fe89c24]], outputs=[]]]] (open inputs: []).
DEBUG main org.qcri.rheem.core.optimizer.enumeration.PlanEnumeration - Concatenating 2x4 plan implementations.
INFO main org.qcri.rheem.core.optimizer.enumeration.PlanEnumeration - Concatenating 2*2=4 concatenation groups (out@Alternative[3x ~Alternative[[TextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl]]], 545de5a4] -> 1 inputs).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@SparkCache[1->1, id=78dc4696] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of out@SparkCache[1->1, id=78dc4696] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@SparkCollect[1->1, id=502f8b57] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of out@SparkCollect[1->1, id=502f8b57] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@SparkCollect[1->1, id=5652f555] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of out@SparkCollect[1->1, id=5652f555] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Setting time estimate of SparkCollect[1->1, id=5652f555] to (0:00:00.016 .. 0:00:00.016, p=81.23%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@SparkObjectFileSink[1->0, id=4fe01805] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of out@SparkObjectFileSource[0->1, id=55120f99] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of out@JavaObjectFileSource[0->1, id=794b435f] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of out@JavaObjectFileSource[0->1, id=38f2e97e] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Setting time estimate of JavaObjectFileSource[0->1, id=38f2e97e] to (0:00:00.082 .. 0:00:00.090, p=85.50%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@SparkObjectFileSink[1->0, id=779dfe55] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Setting time estimate of SparkObjectFileSink[1->0, id=779dfe55] to (0:00:00.063 .. 0:00:00.066, p=85.50%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@SparkTsvFileSink[1->0, id=323659f8] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@SparkCache[1->1, id=1144a55a] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of out@SparkCache[1->1, id=1144a55a] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Setting time estimate of SparkCache[1->1, id=1144a55a] to (0:00:00.371 .. 0:00:00.409, p=81.23%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@SparkCollect[1->1, id=3e521715] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of out@SparkCollect[1->1, id=3e521715] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@SparkCollect[1->1, id=26a529dc] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of out@SparkCollect[1->1, id=26a529dc] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Setting time estimate of SparkCollect[1->1, id=26a529dc] to (0:00:00.016 .. 0:00:00.016, p=81.23%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@SparkObjectFileSink[1->0, id=265c5d69] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@SparkObjectFileSink[1->0, id=1286528d] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Setting time estimate of SparkObjectFileSink[1->0, id=1286528d] to (0:00:00.063 .. 0:00:00.066, p=85.50%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@SparkTsvFileSink[1->0, id=3cc20577] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@SparkCollect[1->1, id=5767b2af] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of out@SparkCollect[1->1, id=5767b2af] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Setting time estimate of SparkCollect[1->1, id=5767b2af] to (0:00:00.016 .. 0:00:00.016, p=81.23%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@JavaCollect[1->1, id=790132f7] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of out@JavaCollect[1->1, id=790132f7] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@SparkBroadcast[1->1, id=2228db21] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of out@SparkBroadcast[1->1, id=2228db21] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of out@SparkCollectionSource[0->1, id=48b0e701] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of out@SparkCollectionSource[0->1, id=241a0c3a] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Setting time estimate of SparkCollectionSource[0->1, id=241a0c3a] to (0:00:00.039 .. 0:00:00.042, p=85.50%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@JavaObjectFileSink[1->0, id=547c04c4] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of out@SparkObjectFileSource[0->1, id=30e92cb9] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of out@SparkObjectFileSource[0->1, id=7fae4d4a] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Setting time estimate of SparkObjectFileSource[0->1, id=7fae4d4a] to (0:00:00.080 .. 0:00:00.087, p=85.50%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of out@JavaObjectFileSource[0->1, id=ba1f559] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@JavaObjectFileSink[1->0, id=3f4f9acd] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Setting time estimate of JavaObjectFileSink[1->0, id=3f4f9acd] to (0:00:00.208 .. 0:00:00.229, p=85.50%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@JavaTsvFileSink[1->0, id=46baf579] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@JavaCollect[1->1, id=4bf324f9] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of out@JavaCollect[1->1, id=4bf324f9] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Setting time estimate of JavaCollect[1->1, id=4bf324f9] to (0:00:00.003 .. 0:00:00.003, p=81.23%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@JavaObjectFileSink[1->0, id=4f7c0be3] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@JavaObjectFileSink[1->0, id=ca66933] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Setting time estimate of JavaObjectFileSink[1->0, id=ca66933] to (0:00:00.208 .. 0:00:00.229, p=85.50%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@JavaTsvFileSink[1->0, id=1d2644e3] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@JavaCollect[1->1, id=705202d1] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of out@JavaCollect[1->1, id=705202d1] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Setting time estimate of JavaCollect[1->1, id=705202d1] to (0:00:00.003 .. 0:00:00.003, p=81.23%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of out@SparkCollectionSource[0->1, id=3e58d65e] from null to (143,419..158,516, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Setting time estimate of SparkCollectionSource[0->1, id=3e58d65e] to (0:00:00.039 .. 0:00:00.042, p=85.50%).
DEBUG main org.qcri.rheem.core.optimizer.enumeration.PlanEnumeration - Created 8 plan implementations.
DEBUG main org.qcri.rheem.core.optimizer.enumeration.PlanEnumerator - 8 implementations for scope [Alternative[3x ~Alternative[[FlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl]]], 5dbe30be], Alternative[3x ~Alternative[[LocalCallbackSink[collect()]]], c7a975a], Alternative[3x ~Alternative[[ReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets]]], 4ebea12c], Alternative[3x ~Alternative[[TextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl]]], 32f0fba8], Alternative[3x ~Alternative[[Filter[my.udf.Sindy.filter1-Filter empty candidate sets]]], 3f2ef586], Alternative[3x ~Alternative[[TextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl]]], 545de5a4], Alternative[3x ~Alternative[[ReduceBy[my.udf.Sindy.reduceBy1-Merge cells]]], 2a1edad4], Alternative[3x ~Alternative[[FlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets]]], 89c10b7], Alternative[3x ~Alternative[[FlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl]]], 4fe89c24], Alternative[3x ~Alternative[[UnionAll[2->1, id=3b220bcb]]], 53e211ee], Alternative[3x ~Alternative[[Map[Prepare cell merging]]], eb6449b]].
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Setting time estimate of JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl] to (0:00:00.049 .. 0:00:00.053, p=85.50%).
DEBUG main org.qcri.rheem.core.optimizer.enumeration.PlanEnumerator - (0:00:05.891 .. 0:00:07.909, p=9.03%): [JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], JavaLocalCallbackSink[collect()], SparkFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets], JavaReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets], JavaFilter[my.udf.Sindy.filter1-Filter empty candidate sets], SparkReduceBy[my.udf.Sindy.reduceBy1-Merge cells], SparkTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], JavaMap[Prepare cell merging], SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], JavaUnionAll[2->1, id=60fa3495]]
DEBUG main org.qcri.rheem.core.optimizer.enumeration.PlanEnumerator - (0:00:01.577 .. 0:00:04.154, p=9.03%): [JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], JavaLocalCallbackSink[collect()], JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], JavaReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets], JavaFilter[my.udf.Sindy.filter1-Filter empty candidate sets], JavaFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets], JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], JavaMap[Prepare cell merging], JavaReduceBy[my.udf.Sindy.reduceBy1-Merge cells], JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], JavaUnionAll[2->1, id=60fa3495]]
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Setting time estimate of SparkTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl] to (0:00:00.084 .. 0:00:00.087, p=85.50%).
DEBUG main org.qcri.rheem.core.optimizer.enumeration.PlanEnumerator - (0:00:05.942 .. 0:00:07.959, p=9.03%): [JavaLocalCallbackSink[collect()], SparkFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets], JavaReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets], JavaFilter[my.udf.Sindy.filter1-Filter empty candidate sets], SparkReduceBy[my.udf.Sindy.reduceBy1-Merge cells], SparkTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], SparkTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], JavaMap[Prepare cell merging], SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], JavaUnionAll[2->1, id=60fa3495]]
DEBUG main org.qcri.rheem.core.optimizer.enumeration.PlanEnumerator - (0:00:06.128 .. 0:00:08.704, p=9.03%): [JavaLocalCallbackSink[collect()], JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], JavaReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets], JavaFilter[my.udf.Sindy.filter1-Filter empty candidate sets], JavaFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets], SparkTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], JavaMap[Prepare cell merging], JavaReduceBy[my.udf.Sindy.reduceBy1-Merge cells], JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], JavaUnionAll[2->1, id=60fa3495]]
DEBUG main org.qcri.rheem.core.optimizer.enumeration.PlanEnumerator - (0:00:05.973 .. 0:00:07.867, p=9.03%): [JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], JavaLocalCallbackSink[collect()], SparkFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets], SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], SparkMap[Prepare cell merging], JavaReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets], JavaFilter[my.udf.Sindy.filter1-Filter empty candidate sets], SparkReduceBy[my.udf.Sindy.reduceBy1-Merge cells], SparkTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], SparkUnionAll[2->1, id=2cf92cc7]]
DEBUG main org.qcri.rheem.core.optimizer.enumeration.PlanEnumerator - (0:00:06.067 .. 0:00:07.866, p=9.03%): [JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], SparkFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets], SparkReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets], SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], SparkMap[Prepare cell merging], SparkReduceBy[my.udf.Sindy.reduceBy1-Merge cells], SparkTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], SparkLocalCallbackSink[collect()], SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], SparkUnionAll[2->1, id=2cf92cc7], SparkFilter[my.udf.Sindy.filter1-Filter empty candidate sets]]
DEBUG main org.qcri.rheem.core.optimizer.enumeration.PlanEnumerator - (0:00:05.966 .. 0:00:07.856, p=9.03%): [JavaLocalCallbackSink[collect()], SparkFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets], SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], SparkMap[Prepare cell merging], JavaReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets], JavaFilter[my.udf.Sindy.filter1-Filter empty candidate sets], SparkReduceBy[my.udf.Sindy.reduceBy1-Merge cells], SparkTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], SparkTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], SparkUnionAll[2->1, id=2cf92cc7]]
DEBUG main org.qcri.rheem.core.optimizer.enumeration.PlanEnumerator - (0:00:06.060 .. 0:00:07.855, p=9.03%): [SparkFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets], SparkReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets], SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], SparkMap[Prepare cell merging], SparkReduceBy[my.udf.Sindy.reduceBy1-Merge cells], SparkTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], SparkTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], SparkLocalCallbackSink[collect()], SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], SparkUnionAll[2->1, id=2cf92cc7], SparkFilter[my.udf.Sindy.filter1-Filter empty candidate sets]]
DEBUG main org.qcri.rheem.core.optimizer.enumeration.LatentOperatorPruningStrategy - (0:00:05.891 .. 0:00:07.909, p=9.03%) < (0:00:05.942 .. 0:00:07.959, p=9.03%): Choosing [JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], JavaLocalCallbackSink[collect()], SparkFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets], JavaReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets], JavaFilter[my.udf.Sindy.filter1-Filter empty candidate sets], SparkReduceBy[my.udf.Sindy.reduceBy1-Merge cells], SparkTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], JavaMap[Prepare cell merging], SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], JavaUnionAll[2->1, id=60fa3495]] over [JavaLocalCallbackSink[collect()], SparkFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets], JavaReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets], JavaFilter[my.udf.Sindy.filter1-Filter empty candidate sets], SparkReduceBy[my.udf.Sindy.reduceBy1-Merge cells], SparkTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], SparkTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], JavaMap[Prepare cell merging], SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], JavaUnionAll[2->1, id=60fa3495]].
DEBUG main org.qcri.rheem.core.optimizer.enumeration.LatentOperatorPruningStrategy - (0:00:05.891 .. 0:00:07.909, p=9.03%) < (0:00:06.128 .. 0:00:08.704, p=9.03%): Choosing [JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], JavaLocalCallbackSink[collect()], SparkFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets], JavaReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets], JavaFilter[my.udf.Sindy.filter1-Filter empty candidate sets], SparkReduceBy[my.udf.Sindy.reduceBy1-Merge cells], SparkTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], JavaMap[Prepare cell merging], SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], JavaUnionAll[2->1, id=60fa3495]] over [JavaLocalCallbackSink[collect()], JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], JavaReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets], JavaFilter[my.udf.Sindy.filter1-Filter empty candidate sets], JavaFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets], SparkTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], JavaMap[Prepare cell merging], JavaReduceBy[my.udf.Sindy.reduceBy1-Merge cells], JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], JavaUnionAll[2->1, id=60fa3495]].
DEBUG main org.qcri.rheem.core.optimizer.enumeration.LatentOperatorPruningStrategy - (0:00:05.891 .. 0:00:07.909, p=9.03%) < (0:00:05.973 .. 0:00:07.867, p=9.03%): Choosing [JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], JavaLocalCallbackSink[collect()], SparkFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets], JavaReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets], JavaFilter[my.udf.Sindy.filter1-Filter empty candidate sets], SparkReduceBy[my.udf.Sindy.reduceBy1-Merge cells], SparkTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], JavaMap[Prepare cell merging], SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], JavaUnionAll[2->1, id=60fa3495]] over [JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], JavaLocalCallbackSink[collect()], SparkFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets], SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], SparkMap[Prepare cell merging], JavaReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets], JavaFilter[my.udf.Sindy.filter1-Filter empty candidate sets], SparkReduceBy[my.udf.Sindy.reduceBy1-Merge cells], SparkTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], SparkUnionAll[2->1, id=2cf92cc7]].
DEBUG main org.qcri.rheem.core.optimizer.enumeration.LatentOperatorPruningStrategy - (0:00:05.891 .. 0:00:07.909, p=9.03%) < (0:00:06.067 .. 0:00:07.866, p=9.03%): Choosing [JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], JavaLocalCallbackSink[collect()], SparkFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets], JavaReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets], JavaFilter[my.udf.Sindy.filter1-Filter empty candidate sets], SparkReduceBy[my.udf.Sindy.reduceBy1-Merge cells], SparkTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], JavaMap[Prepare cell merging], SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], JavaUnionAll[2->1, id=60fa3495]] over [JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], SparkFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets], SparkReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets], SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], SparkMap[Prepare cell merging], SparkReduceBy[my.udf.Sindy.reduceBy1-Merge cells], SparkTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], SparkLocalCallbackSink[collect()], SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], SparkUnionAll[2->1, id=2cf92cc7], SparkFilter[my.udf.Sindy.filter1-Filter empty candidate sets]].
DEBUG main org.qcri.rheem.core.optimizer.enumeration.LatentOperatorPruningStrategy - (0:00:05.891 .. 0:00:07.909, p=9.03%) < (0:00:05.966 .. 0:00:07.856, p=9.03%): Choosing [JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], JavaLocalCallbackSink[collect()], SparkFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets], JavaReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets], JavaFilter[my.udf.Sindy.filter1-Filter empty candidate sets], SparkReduceBy[my.udf.Sindy.reduceBy1-Merge cells], SparkTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], JavaMap[Prepare cell merging], SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], JavaUnionAll[2->1, id=60fa3495]] over [JavaLocalCallbackSink[collect()], SparkFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets], SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], SparkMap[Prepare cell merging], JavaReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets], JavaFilter[my.udf.Sindy.filter1-Filter empty candidate sets], SparkReduceBy[my.udf.Sindy.reduceBy1-Merge cells], SparkTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], SparkTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], SparkUnionAll[2->1, id=2cf92cc7]].
DEBUG main org.qcri.rheem.core.optimizer.enumeration.PlanEnumerator - Pruned plan enumeration from 8 to 3 implementations.
DEBUG main org.qcri.rheem.core.api.Job - Enumerated 3 plans.
DEBUG main org.qcri.rheem.core.api.Job - Plan with operators: [JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], JavaLocalCallbackSink[collect()], SparkFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets], JavaReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets], JavaFilter[my.udf.Sindy.filter1-Filter empty candidate sets], SparkReduceBy[my.udf.Sindy.reduceBy1-Merge cells], SparkTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], JavaMap[Prepare cell merging], SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], JavaUnionAll[2->1, id=60fa3495]]
DEBUG main org.qcri.rheem.core.api.Job - Plan with operators: [JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], JavaLocalCallbackSink[collect()], JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], JavaReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets], JavaFilter[my.udf.Sindy.filter1-Filter empty candidate sets], JavaFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets], JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], JavaMap[Prepare cell merging], JavaReduceBy[my.udf.Sindy.reduceBy1-Merge cells], JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], JavaUnionAll[2->1, id=60fa3495]]
DEBUG main org.qcri.rheem.core.api.Job - Plan with operators: [SparkFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets], SparkReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets], SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], SparkMap[Prepare cell merging], SparkReduceBy[my.udf.Sindy.reduceBy1-Merge cells], SparkTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl], SparkTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], SparkLocalCallbackSink[collect()], SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl], SparkUnionAll[2->1, id=2cf92cc7], SparkFilter[my.udf.Sindy.filter1-Filter empty candidate sets]]
INFO main org.qcri.rheem.core.api.Job - Picked PlanImplementation[[Platform[Java Streams]], (0:00:01.577 .. 0:00:04.154, p=9.03%), costs=(1,577.00..4,154.00 ~ 9.0%) selecitvityKey: ] as best plan.
INFO main org.qcri.rheem.core.api.Job - Compiling execution plan...
DEBUG main org.qcri.rheem.core.optimizer.enumeration.ExecutionTaskFlowCompiler$Activator - Connecting output@JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl] -> Junction[output@JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl]->[in@JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl]]].
DEBUG main org.qcri.rheem.core.optimizer.enumeration.ExecutionTaskFlowCompiler$Activator - Connecting output@JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl] -> Junction[output@JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl]->[in@JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl]]].
DEBUG main org.qcri.rheem.core.optimizer.enumeration.ExecutionTaskFlowCompiler$Activator - Connecting out@JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl] -> Junction[out@JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl]->[in1@JavaUnionAll[2->1, id=60fa3495]]].
DEBUG main org.qcri.rheem.core.optimizer.enumeration.ExecutionTaskFlowCompiler$Activator - Connecting out@JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl] -> Junction[out@JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl]->[in0@JavaUnionAll[2->1, id=60fa3495]]].
DEBUG main org.qcri.rheem.core.optimizer.enumeration.ExecutionTaskFlowCompiler$Activator - Connecting out@JavaUnionAll[2->1, id=60fa3495] -> Junction[out@JavaUnionAll[2->1, id=60fa3495]->[in@JavaMap[Prepare cell merging]]].
DEBUG main org.qcri.rheem.core.optimizer.enumeration.ExecutionTaskFlowCompiler$Activator - Connecting out@JavaMap[Prepare cell merging] -> Junction[out@JavaMap[Prepare cell merging]->[in@JavaReduceBy[my.udf.Sindy.reduceBy1-Merge cells]]].
DEBUG main org.qcri.rheem.core.optimizer.enumeration.ExecutionTaskFlowCompiler$Activator - Connecting out@JavaReduceBy[my.udf.Sindy.reduceBy1-Merge cells] -> Junction[out@JavaReduceBy[my.udf.Sindy.reduceBy1-Merge cells]->[in@JavaFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets]]].
DEBUG main org.qcri.rheem.core.optimizer.enumeration.ExecutionTaskFlowCompiler$Activator - Connecting out@JavaFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets] -> Junction[out@JavaFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets]->[in@JavaReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets]]].
DEBUG main org.qcri.rheem.core.optimizer.enumeration.ExecutionTaskFlowCompiler$Activator - Connecting out@JavaReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets] -> Junction[out@JavaReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets]->[in@JavaFilter[my.udf.Sindy.filter1-Filter empty candidate sets]]].
DEBUG main org.qcri.rheem.core.optimizer.enumeration.ExecutionTaskFlowCompiler$Activator - Connecting out@JavaFilter[my.udf.Sindy.filter1-Filter empty candidate sets] -> Junction[out@JavaFilter[my.udf.Sindy.filter1-Filter empty candidate sets]->[in@JavaLocalCallbackSink[collect()]]].
DEBUG main org.qcri.rheem.core.optimizer.enumeration.StageAssignmentTraversal - Established initial stage with [T[JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl]], T[JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl]], T[JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl]], T[JavaFilter[my.udf.Sindy.filter1-Filter empty candidate sets]], T[JavaUnionAll[2->1, id=60fa3495]], T[JavaFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets]], T[JavaReduceBy[my.udf.Sindy.reduceBy1-Merge cells]], T[JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl]], T[JavaMap[Prepare cell merging]], T[JavaReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets]], T[JavaLocalCallbackSink[collect()]]].
DEBUG main org.qcri.rheem.core.optimizer.enumeration.StageAssignmentTraversal - Separating [T[JavaFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets]], T[JavaFilter[my.udf.Sindy.filter1-Filter empty candidate sets]], T[JavaReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets]], T[JavaLocalCallbackSink[collect()]]] from [T[JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl]], T[JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl]], T[JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl]], T[JavaUnionAll[2->1, id=60fa3495]], T[JavaReduceBy[my.udf.Sindy.reduceBy1-Merge cells]], T[JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl]], T[JavaMap[Prepare cell merging]]]...
DEBUG main org.qcri.rheem.core.optimizer.enumeration.StageAssignmentTraversal - Separating [T[JavaFilter[my.udf.Sindy.filter1-Filter empty candidate sets]], T[JavaLocalCallbackSink[collect()]]] from [T[JavaFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets]], T[JavaReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets]]]...
DEBUG main org.qcri.rheem.core.optimizer.enumeration.StageAssignmentTraversal - Updated required stages of T[JavaFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets]] to [InterimStage[T[JavaFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets]]], InterimStage[T[JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl]], T[JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl]]]].
DEBUG main org.qcri.rheem.core.optimizer.enumeration.StageAssignmentTraversal - Updated required stages of T[JavaReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets]] to [InterimStage[T[JavaFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets]]], InterimStage[T[JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl]], T[JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl]]]].
DEBUG main org.qcri.rheem.core.optimizer.enumeration.StageAssignmentTraversal - Updated required stages of T[JavaFilter[my.udf.Sindy.filter1-Filter empty candidate sets]] to [InterimStage[T[JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl]], T[JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl]]], InterimStage[T[JavaFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets]]], InterimStage[T[JavaFilter[my.udf.Sindy.filter1-Filter empty candidate sets]]]].
DEBUG main org.qcri.rheem.core.optimizer.enumeration.StageAssignmentTraversal - Updated required stages of T[JavaLocalCallbackSink[collect()]] to [InterimStage[T[JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl]], T[JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl]]], InterimStage[T[JavaFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets]]], InterimStage[T[JavaFilter[my.udf.Sindy.filter1-Filter empty candidate sets]]]].
DEBUG main org.qcri.rheem.core.optimizer.enumeration.StageAssignmentTraversal - No separable tasks found in marked stage InterimStage[T[JavaFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets]]].
DEBUG main org.qcri.rheem.core.optimizer.enumeration.StageAssignmentTraversal - No separable tasks found in marked stage InterimStage[T[JavaFilter[my.udf.Sindy.filter1-Filter empty candidate sets]]].
DEBUG main org.qcri.rheem.core.optimizer.enumeration.StageAssignmentTraversal - Final stage InterimStage[T[JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl]], T[JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl]]]: [T[JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl]], T[JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl]], T[JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl]], T[JavaUnionAll[2->1, id=60fa3495]], T[JavaReduceBy[my.udf.Sindy.reduceBy1-Merge cells]], T[JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl]], T[JavaMap[Prepare cell merging]]]
DEBUG main org.qcri.rheem.core.optimizer.enumeration.StageAssignmentTraversal - Final stage InterimStage[T[JavaFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets]]]: [T[JavaFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets]], T[JavaReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets]]]
DEBUG main org.qcri.rheem.core.optimizer.enumeration.StageAssignmentTraversal - Final stage InterimStage[T[JavaFilter[my.udf.Sindy.filter1-Filter empty candidate sets]]]: [T[JavaFilter[my.udf.Sindy.filter1-Filter empty candidate sets]], T[JavaLocalCallbackSink[collect()]]]
DEBUG main org.qcri.rheem.core.optimizer.enumeration.PlanImplementation - >>> Regular operators
DEBUG main org.qcri.rheem.core.optimizer.enumeration.PlanImplementation - Estimated execution time of JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl]: (0:00:00.049 .. 0:00:00.053, p=85.50%)
DEBUG main org.qcri.rheem.core.optimizer.enumeration.PlanImplementation - Estimated execution time of JavaLocalCallbackSink[collect()]: (0:00:00.002 .. 0:00:00.002, p=85.50%)
DEBUG main org.qcri.rheem.core.optimizer.enumeration.PlanImplementation - Estimated execution time of JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl]: (0:00:00.202 .. 0:00:00.649, p=18.05%)
DEBUG main org.qcri.rheem.core.optimizer.enumeration.PlanImplementation - Estimated execution time of JavaReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets]: (0:00:00.217 .. 0:00:00.509, p=9.03%)
DEBUG main org.qcri.rheem.core.optimizer.enumeration.PlanImplementation - Estimated execution time of JavaFilter[my.udf.Sindy.filter1-Filter empty candidate sets]: (0:00:00.003 .. 0:00:00.003, p=18.05%)
DEBUG main org.qcri.rheem.core.optimizer.enumeration.PlanImplementation - Estimated execution time of JavaFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets]: (0:00:00.243 .. 0:00:00.802, p=18.05%)
DEBUG main org.qcri.rheem.core.optimizer.enumeration.PlanImplementation - Estimated execution time of JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_1/orders.tbl]: (0:00:00.080 .. 0:00:00.191, p=18.05%)
DEBUG main org.qcri.rheem.core.optimizer.enumeration.PlanImplementation - Estimated execution time of JavaMap[Prepare cell merging]: (0:00:00.070 .. 0:00:00.619, p=18.05%)
DEBUG main org.qcri.rheem.core.optimizer.enumeration.PlanImplementation - Estimated execution time of JavaReduceBy[my.udf.Sindy.reduceBy1-Merge cells]: (0:00:00.524 .. 0:00:01.121, p=9.03%)
DEBUG main org.qcri.rheem.core.optimizer.enumeration.PlanImplementation - Estimated execution time of JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_1/lineitem.tbl]: (0:00:00.185 .. 0:00:00.203, p=85.50%)
DEBUG main org.qcri.rheem.core.optimizer.enumeration.PlanImplementation - Estimated execution time of JavaUnionAll[2->1, id=60fa3495]: (0:00:00.002 .. 0:00:00.002, p=77.16%)
DEBUG main org.qcri.rheem.core.optimizer.enumeration.PlanImplementation - >>> Glue operators
DEBUG main org.qcri.rheem.core.optimizer.enumeration.PlanImplementation - >>> Loops
WARN main org.qcri.rheem.core.profiling.CardinalityRepository - Cardinality repository currently disabled.
INFO main org.qcri.rheem.core.profiling.ExecutionLog - Curating execution log at /home/jonas.kemper/.rheem/executions.json.
INFO main org.qcri.rheem.core.api.Job - Accumulated execution time: 0:00:00.000 (0 ms) (effective: 0:00:00.000 (0 ms), overhead: 0:00:00.000 (0 ms))
INFO main org.qcri.rheem.core.api.Job - Estimated execution time (plan 1): (0:00:01.577 .. 0:00:04.154, p=9.03%)
INFO main org.qcri.rheem.core.api.Job - Accumulated costs: 0.00 .. 0.00
INFO main org.qcri.rheem.core.api.Job - Estimated costs (plan 1): (1,577.00..4,154.00 ~ 9.0%) selecitvityKey: 
INFO main org.qcri.rheem.core.api.Job - Plan metrics: 11 virtual operators, 22 execution operators, 11 alternatives, 2048 combinations
INFO main org.qcri.rheem.core.api.Job - StopWatch results:
* Optimization                            - 0:00:00.711
  * Prepare                               - 0:00:00.105
    * Prune&Isolate                       - 0:00:00.013
    * Transformations                     - 0:00:00.091
    * Sanity                              - 0:00:00.000
  * Cardinality&Load Estimation           - 0:00:00.334
    * Create c                            - 0:00:00.334
    * Create CardinalityEstimationManager - 0:00:00.000
    * Push Estimation                     - 0:00:00.325
      * Estimate source cardinalities     - 0:00:00.243
  * Create Initial Execution Plan         - 0:00:00.271
    * Enumerate                           - 0:00:00.242
      * Concatenation                     - 0:00:00.142
        * Channel Conversion              - 0:00:00.125
      * Prune                             - 0:00:00.075
    * Pick Best Plan                      - 0:00:00.004
    * Split Stages                        - 0:00:00.019
* Execution                               - 0:00:00.008
  * Execution 0                           - 0:00:00.008
* Post-processing                         - 0:00:00.006
  * Log measurements                      - 0:00:00.006
  * Release Resources                     - 0:00:00.000
DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@264f218
DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@264f218
DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@264f218
DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper: closed
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper: stopped, remaining connections 0
INFO main org.qcri.rheem.core.api.Configuration - Using configuration at file:/home/jonas.kemper/MA-Scripts/benchmark-thor-validation-July19-20uhr07.properties.
INFO main org.qcri.rheem.core.util.fs.HadoopFileSystem - Adding handler for HDFS URLs.
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Falling back to shell based
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: jonas.kemper
DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "UnixPrincipal: jonas.kemper" with name jonas.kemper
DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "jonas.kemper"
DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:jonas.kemper (auth:SIMPLE)
DEBUG main  - address: thor01/172.16.64.55 isLoopbackAddress: false, with host 172.16.64.55 thor01
DEBUG main io.netty.util.internal.logging.InternalLoggerFactory - Using SLF4J as the default logging framework
DEBUG main io.netty.util.internal.PlatformDependent0 - java.nio.Buffer.address: available
DEBUG main io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.theUnsafe: available
DEBUG main io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.copyMemory: available
DEBUG main io.netty.util.internal.PlatformDependent0 - java.nio.Bits.unaligned: true
DEBUG main io.netty.util.internal.PlatformDependent - Java version: 8
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.noUnsafe: false
DEBUG main io.netty.util.internal.PlatformDependent - sun.misc.Unsafe: available
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.noJavassist: false
DEBUG main io.netty.util.internal.PlatformDependent - Javassist: unavailable
DEBUG main io.netty.util.internal.PlatformDependent - You don't have Javassist in your class path or you don't have enough permission to load dynamically generated classes.  Please check the configuration for better performance.
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.tmpdir: /tmp (java.io.tmpdir)
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.bitMode: 64 (sun.arch.data.model)
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.noPreferDirect: false
DEBUG main io.netty.util.internal.NativeLibraryLoader - -Dio.netty.tmpdir: /tmp (java.io.tmpdir)
DEBUG main io.netty.util.internal.NativeLibraryLoader - -Dio.netty.netty.workdir: /tmp (io.netty.tmpdir)
DEBUG main io.netty.util.NetUtil - Loopback interface: lo (lo, 0:0:0:0:0:0:0:1%lo)
DEBUG main io.netty.util.NetUtil - /proc/sys/net/core/somaxconn: 128
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
DEBUG main org.apache.hadoop.hdfs.DFSClient - No KeyProvider found.
DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@7283d3eb
DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@264f218
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Both short-circuit local reads and UNIX domain socket are disabled.
DEBUG main org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
DEBUG main org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
DEBUG main org.apache.hadoop.ipc.Client - Connecting to thor01/172.16.64.55:8020
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper: starting, having connections 1
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper sending #0
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper got value #0
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 74ms
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper sending #1
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper got value #1
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 1ms
INFO main org.qcri.rheem.core.api.Job - Preparing plan...
DEBUG main org.qcri.rheem.core.mapping.PlanTransformation - Replacing TextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] with SparkTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] in epoch 1.
DEBUG main org.qcri.rheem.core.mapping.PlanTransformation - Replacing TextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] with SparkTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] in epoch 1.
DEBUG main org.qcri.rheem.core.mapping.PlanTransformation - Replacing Map[Prepare cell merging] with SparkMap[Prepare cell merging] in epoch 1.
DEBUG main org.qcri.rheem.core.mapping.PlanTransformation - Replacing ReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets] with SparkReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets] in epoch 1.
DEBUG main org.qcri.rheem.core.mapping.PlanTransformation - Replacing ReduceBy[my.udf.Sindy.reduceBy1-Merge cells] with SparkReduceBy[my.udf.Sindy.reduceBy1-Merge cells] in epoch 1.
DEBUG main org.qcri.rheem.core.mapping.PlanTransformation - Replacing LocalCallbackSink[collect()] with SparkLocalCallbackSink[collect()] in epoch 1.
DEBUG main org.qcri.rheem.core.mapping.PlanTransformation - Replacing FlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets] with SparkFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets] in epoch 1.
DEBUG main org.qcri.rheem.core.mapping.PlanTransformation - Replacing FlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] with SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] in epoch 1.
DEBUG main org.qcri.rheem.core.mapping.PlanTransformation - Replacing FlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] with SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] in epoch 1.
DEBUG main org.qcri.rheem.core.mapping.PlanTransformation - Replacing Filter[my.udf.Sindy.filter1-Filter empty candidate sets] with SparkFilter[my.udf.Sindy.filter1-Filter empty candidate sets] in epoch 1.
DEBUG main org.qcri.rheem.core.mapping.PlanTransformation - Replacing UnionAll[2->1, id=3b220bcb] with SparkUnionAll[2->1, id=2cf92cc7] in epoch 1.
DEBUG main org.qcri.rheem.core.mapping.PlanTransformation - Replacing TextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] with JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] in epoch 1.
DEBUG main org.qcri.rheem.core.mapping.PlanTransformation - Replacing TextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] with JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] in epoch 1.
DEBUG main org.qcri.rheem.core.mapping.PlanTransformation - Replacing Map[Prepare cell merging] with JavaMap[Prepare cell merging] in epoch 1.
DEBUG main org.qcri.rheem.core.mapping.PlanTransformation - Replacing ReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets] with JavaReduceBy[my.udf.Sindy.reduceBy2-Merge IND candidate sets] in epoch 1.
DEBUG main org.qcri.rheem.core.mapping.PlanTransformation - Replacing ReduceBy[my.udf.Sindy.reduceBy1-Merge cells] with JavaReduceBy[my.udf.Sindy.reduceBy1-Merge cells] in epoch 1.
DEBUG main org.qcri.rheem.core.mapping.PlanTransformation - Replacing LocalCallbackSink[collect()] with JavaLocalCallbackSink[collect()] in epoch 1.
DEBUG main org.qcri.rheem.core.mapping.PlanTransformation - Replacing FlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets] with JavaFlatMap[my.udf.Sindy.flatmap2-Generate IND candidate sets] in epoch 1.
DEBUG main org.qcri.rheem.core.mapping.PlanTransformation - Replacing FlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] with JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] in epoch 1.
DEBUG main org.qcri.rheem.core.mapping.PlanTransformation - Replacing FlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] with JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] in epoch 1.
DEBUG main org.qcri.rheem.core.mapping.PlanTransformation - Replacing Filter[my.udf.Sindy.filter1-Filter empty candidate sets] with JavaFilter[my.udf.Sindy.filter1-Filter empty candidate sets] in epoch 1.
DEBUG main org.qcri.rheem.core.mapping.PlanTransformation - Replacing UnionAll[2->1, id=3b220bcb] with JavaUnionAll[2->1, id=60fa3495] in epoch 1.
DEBUG main org.qcri.rheem.core.plan.rheemplan.RheemPlan - Applied 22 transformations in epoch 1.
DEBUG main org.qcri.rheem.core.plan.rheemplan.RheemPlan - Applied 0 transformations in epoch 2.
INFO main org.qcri.rheem.core.api.Job - Estimating cardinalities and execution load...
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper sending #2
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper got value #2
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 1ms
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper sending #3
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper got value #3
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 1ms
DEBUG main org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=380176680
  underConstruction=false
  blocks=[LocatedBlock{BP-1353461958-172.16.64.55-1481544420468:blk_1073765142_24486; getBlockSize()=134217728; corrupt=false; offset=0; locs=[172.16.64.55:50010, 172.16.64.58:50010, 172.16.64.56:50010]; storageIDs=[DS-d6891cfc-172e-4751-b68c-f5c3754d7e1e, DS-cd34c45a-acfc-4880-b180-f785e6eb4939, DS-eb0a15ee-718e-4ab0-8d76-b3f9ea35384a]; storageTypes=[DISK, DISK, DISK]}, LocatedBlock{BP-1353461958-172.16.64.55-1481544420468:blk_1073765143_24487; getBlockSize()=134217728; corrupt=false; offset=134217728; locs=[172.16.64.55:50010, 172.16.64.56:50010, 172.16.64.58:50010]; storageIDs=[DS-d6891cfc-172e-4751-b68c-f5c3754d7e1e, DS-eb0a15ee-718e-4ab0-8d76-b3f9ea35384a, DS-cd34c45a-acfc-4880-b180-f785e6eb4939]; storageTypes=[DISK, DISK, DISK]}, LocatedBlock{BP-1353461958-172.16.64.55-1481544420468:blk_1073765144_24488; getBlockSize()=111741224; corrupt=false; offset=268435456; locs=[172.16.64.55:50010, 172.16.64.57:50010, 172.16.64.56:50010]; storageIDs=[DS-d6891cfc-172e-4751-b68c-f5c3754d7e1e, DS-958ffb1d-b20b-4de1-8ce6-a034f737bdee, DS-eb0a15ee-718e-4ab0-8d76-b3f9ea35384a]; storageTypes=[DISK, DISK, DISK]}]
  lastLocatedBlock=LocatedBlock{BP-1353461958-172.16.64.55-1481544420468:blk_1073765144_24488; getBlockSize()=111741224; corrupt=false; offset=268435456; locs=[172.16.64.55:50010, 172.16.64.57:50010, 172.16.64.56:50010]; storageIDs=[DS-d6891cfc-172e-4751-b68c-f5c3754d7e1e, DS-958ffb1d-b20b-4de1-8ce6-a034f737bdee, DS-eb0a15ee-718e-4ab0-8d76-b3f9ea35384a]; storageTypes=[DISK, DISK, DISK]}
  isLastBlockComplete=true}
DEBUG main org.apache.hadoop.hdfs.DFSClient - Connecting to datanode 172.16.64.55:50010
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper sending #4
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper got value #4
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getServerDefaults took 1ms
DEBUG main org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient - SASL client skipping handshake in unsecured configuration for addr = /172.16.64.55, datanodeId = 172.16.64.55:50010
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of out@TextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] from null to (2,911,521..3,217,997, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@Alternative[3x ~Alternative[[FlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl]]], 5dbe30be] from null to (2,911,521..3,217,997, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@FlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] from null to (2,911,521..3,217,997, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] from null to (2,911,521..3,217,997, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] from null to (2,911,521..3,217,997, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of output@SparkTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] from null to (2,911,521..3,217,997, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Setting time estimate of SparkTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] to (0:00:00.281 .. 0:00:00.309, p=85.50%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@Alternative[3x ~Alternative[[FlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl]]], 5dbe30be] from (2,911,521..3,217,997, 95.00%) to (2,911,521..3,217,997, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@FlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] from (2,911,521..3,217,997, 95.00%) to (2,911,521..3,217,997, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] from (2,911,521..3,217,997, 95.00%) to (2,911,521..3,217,997, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] from (2,911,521..3,217,997, 95.00%) to (2,911,521..3,217,997, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of output@JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] from null to (2,911,521..3,217,997, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Setting time estimate of JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] to (0:00:00.919 .. 0:00:01.017, p=85.50%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@Alternative[3x ~Alternative[[FlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl]]], 5dbe30be] from (2,911,521..3,217,997, 95.00%) to (2,911,521..3,217,997, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@FlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] from (2,911,521..3,217,997, 95.00%) to (2,911,521..3,217,997, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] from (2,911,521..3,217,997, 95.00%) to (2,911,521..3,217,997, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] from (2,911,521..3,217,997, 95.00%) to (2,911,521..3,217,997, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of out@Alternative[3x ~Alternative[[TextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl]]], 32f0fba8] from null to (2,911,521..3,217,997, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@Alternative[3x ~Alternative[[FlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl]]], 5dbe30be] from (2,911,521..3,217,997, 95.00%) to (2,911,521..3,217,997, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@FlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] from (2,911,521..3,217,997, 95.00%) to (2,911,521..3,217,997, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] from (2,911,521..3,217,997, 95.00%) to (2,911,521..3,217,997, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] from (2,911,521..3,217,997, 95.00%) to (2,911,521..3,217,997, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of out@TextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] from (2,911,521..3,217,997, 95.00%) to (2,911,521..3,217,997, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@Alternative[3x ~Alternative[[FlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl]]], 5dbe30be] from (2,911,521..3,217,997, 95.00%) to (2,911,521..3,217,997, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@FlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] from (2,911,521..3,217,997, 95.00%) to (2,911,521..3,217,997, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] from (2,911,521..3,217,997, 95.00%) to (2,911,521..3,217,997, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] from (2,911,521..3,217,997, 95.00%) to (2,911,521..3,217,997, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of output@SparkTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] from (2,911,521..3,217,997, 95.00%) to (2,911,521..3,217,997, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@Alternative[3x ~Alternative[[FlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl]]], 5dbe30be] from (2,911,521..3,217,997, 95.00%) to (2,911,521..3,217,997, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@FlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] from (2,911,521..3,217,997, 95.00%) to (2,911,521..3,217,997, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] from (2,911,521..3,217,997, 95.00%) to (2,911,521..3,217,997, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] from (2,911,521..3,217,997, 95.00%) to (2,911,521..3,217,997, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of output@JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] from (2,911,521..3,217,997, 95.00%) to (2,911,521..3,217,997, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@Alternative[3x ~Alternative[[FlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl]]], 5dbe30be] from (2,911,521..3,217,997, 95.00%) to (2,911,521..3,217,997, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@FlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] from (2,911,521..3,217,997, 95.00%) to (2,911,521..3,217,997, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] from (2,911,521..3,217,997, 95.00%) to (2,911,521..3,217,997, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] from (2,911,521..3,217,997, 95.00%) to (2,911,521..3,217,997, 95.00%).
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper sending #5
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper got value #5
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 1ms
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper sending #6
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper got value #6
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 1ms
DEBUG main org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=85875294
  underConstruction=false
  blocks=[LocatedBlock{BP-1353461958-172.16.64.55-1481544420468:blk_1073765146_24490; getBlockSize()=85875294; corrupt=false; offset=0; locs=[172.16.64.55:50010, 172.16.64.57:50010, 172.16.64.56:50010]; storageIDs=[DS-d6891cfc-172e-4751-b68c-f5c3754d7e1e, DS-958ffb1d-b20b-4de1-8ce6-a034f737bdee, DS-eb0a15ee-718e-4ab0-8d76-b3f9ea35384a]; storageTypes=[DISK, DISK, DISK]}]
  lastLocatedBlock=LocatedBlock{BP-1353461958-172.16.64.55-1481544420468:blk_1073765146_24490; getBlockSize()=85875294; corrupt=false; offset=0; locs=[172.16.64.55:50010, 172.16.64.57:50010, 172.16.64.56:50010]; storageIDs=[DS-d6891cfc-172e-4751-b68c-f5c3754d7e1e, DS-958ffb1d-b20b-4de1-8ce6-a034f737bdee, DS-eb0a15ee-718e-4ab0-8d76-b3f9ea35384a]; storageTypes=[DISK, DISK, DISK]}
  isLastBlockComplete=true}
DEBUG main org.apache.hadoop.hdfs.DFSClient - Connecting to datanode 172.16.64.55:50010
DEBUG main org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient - SASL client skipping handshake in unsecured configuration for addr = /172.16.64.55, datanodeId = 172.16.64.55:50010
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of out@TextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] from null to (725,894..802,304, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@Alternative[3x ~Alternative[[FlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl]]], 4fe89c24] from null to (725,894..802,304, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@FlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] from null to (725,894..802,304, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] from null to (725,894..802,304, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] from null to (725,894..802,304, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of output@SparkTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] from null to (725,894..802,304, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Setting time estimate of SparkTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] to (0:00:00.097 .. 0:00:00.105, p=85.50%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@Alternative[3x ~Alternative[[FlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl]]], 4fe89c24] from (725,894..802,304, 95.00%) to (725,894..802,304, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@FlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] from (725,894..802,304, 95.00%) to (725,894..802,304, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] from (725,894..802,304, 95.00%) to (725,894..802,304, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] from (725,894..802,304, 95.00%) to (725,894..802,304, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of output@JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] from null to (725,894..802,304, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Setting time estimate of JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] to (0:00:00.231 .. 0:00:00.255, p=85.50%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@Alternative[3x ~Alternative[[FlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl]]], 4fe89c24] from (725,894..802,304, 95.00%) to (725,894..802,304, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@FlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] from (725,894..802,304, 95.00%) to (725,894..802,304, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] from (725,894..802,304, 95.00%) to (725,894..802,304, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] from (725,894..802,304, 95.00%) to (725,894..802,304, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of out@Alternative[3x ~Alternative[[TextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl]]], 545de5a4] from null to (725,894..802,304, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@Alternative[3x ~Alternative[[FlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl]]], 4fe89c24] from (725,894..802,304, 95.00%) to (725,894..802,304, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@FlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] from (725,894..802,304, 95.00%) to (725,894..802,304, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] from (725,894..802,304, 95.00%) to (725,894..802,304, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] from (725,894..802,304, 95.00%) to (725,894..802,304, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of out@TextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] from (725,894..802,304, 95.00%) to (725,894..802,304, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@Alternative[3x ~Alternative[[FlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl]]], 4fe89c24] from (725,894..802,304, 95.00%) to (725,894..802,304, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@FlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] from (725,894..802,304, 95.00%) to (725,894..802,304, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] from (725,894..802,304, 95.00%) to (725,894..802,304, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] from (725,894..802,304, 95.00%) to (725,894..802,304, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of output@SparkTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] from (725,894..802,304, 95.00%) to (725,894..802,304, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@Alternative[3x ~Alternative[[FlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl]]], 4fe89c24] from (725,894..802,304, 95.00%) to (725,894..802,304, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@FlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] from (725,894..802,304, 95.00%) to (725,894..802,304, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] from (725,894..802,304, 95.00%) to (725,894..802,304, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] from (725,894..802,304, 95.00%) to (725,894..802,304, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of output@JavaTextFileSource[Load hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] from (725,894..802,304, 95.00%) to (725,894..802,304, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@Alternative[3x ~Alternative[[FlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl]]], 4fe89c24] from (725,894..802,304, 95.00%) to (725,894..802,304, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@FlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] from (725,894..802,304, 95.00%) to (725,894..802,304, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] from (725,894..802,304, 95.00%) to (725,894..802,304, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in@JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] from (725,894..802,304, 95.00%) to (725,894..802,304, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of out@FlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] from null to (2,944,662..3,277,827, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in0@Alternative[3x ~Alternative[[UnionAll[2->1, id=3b220bcb]]], 53e211ee] from null to (2,944,662..3,277,827, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in0@UnionAll[2->1, id=3b220bcb] from null to (2,944,662..3,277,827, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in0@SparkUnionAll[2->1, id=2cf92cc7] from null to (2,944,662..3,277,827, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in0@JavaUnionAll[2->1, id=60fa3495] from null to (2,944,662..3,277,827, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of out@SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] from null to (2,944,662..3,277,827, 95.00%).
WARN main org.qcri.rheem.core.api.configuration.FunctionalKeyValueProvider - Creating fallback load estimator for FlatMapDescriptor[org.qcri.rheem.apps.sindy.Sindy$CellCreator@6f6a7463].
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Setting time estimate of SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] to (0:00:00.761 .. 0:00:01.927, p=18.05%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in0@Alternative[3x ~Alternative[[UnionAll[2->1, id=3b220bcb]]], 53e211ee] from (2,944,662..3,277,827, 95.00%) to (2,944,662..3,277,827, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in0@UnionAll[2->1, id=3b220bcb] from (2,944,662..3,277,827, 95.00%) to (2,944,662..3,277,827, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in0@SparkUnionAll[2->1, id=2cf92cc7] from (2,944,662..3,277,827, 95.00%) to (2,944,662..3,277,827, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in0@JavaUnionAll[2->1, id=60fa3495] from (2,944,662..3,277,827, 95.00%) to (2,944,662..3,277,827, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of out@JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] from null to (2,944,662..3,277,827, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Setting time estimate of JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] to (0:00:00.863 .. 0:00:03.116, p=18.05%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in0@Alternative[3x ~Alternative[[UnionAll[2->1, id=3b220bcb]]], 53e211ee] from (2,944,662..3,277,827, 95.00%) to (2,944,662..3,277,827, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in0@UnionAll[2->1, id=3b220bcb] from (2,944,662..3,277,827, 95.00%) to (2,944,662..3,277,827, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in0@SparkUnionAll[2->1, id=2cf92cc7] from (2,944,662..3,277,827, 95.00%) to (2,944,662..3,277,827, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in0@JavaUnionAll[2->1, id=60fa3495] from (2,944,662..3,277,827, 95.00%) to (2,944,662..3,277,827, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of out@Alternative[3x ~Alternative[[FlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl]]], 5dbe30be] from null to (2,944,662..3,277,827, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in0@Alternative[3x ~Alternative[[UnionAll[2->1, id=3b220bcb]]], 53e211ee] from (2,944,662..3,277,827, 95.00%) to (2,944,662..3,277,827, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in0@UnionAll[2->1, id=3b220bcb] from (2,944,662..3,277,827, 95.00%) to (2,944,662..3,277,827, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in0@SparkUnionAll[2->1, id=2cf92cc7] from (2,944,662..3,277,827, 95.00%) to (2,944,662..3,277,827, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in0@JavaUnionAll[2->1, id=60fa3495] from (2,944,662..3,277,827, 95.00%) to (2,944,662..3,277,827, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of out@FlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] from (2,944,662..3,277,827, 95.00%) to (2,944,662..3,277,827, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in0@Alternative[3x ~Alternative[[UnionAll[2->1, id=3b220bcb]]], 53e211ee] from (2,944,662..3,277,827, 95.00%) to (2,944,662..3,277,827, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in0@UnionAll[2->1, id=3b220bcb] from (2,944,662..3,277,827, 95.00%) to (2,944,662..3,277,827, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in0@SparkUnionAll[2->1, id=2cf92cc7] from (2,944,662..3,277,827, 95.00%) to (2,944,662..3,277,827, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in0@JavaUnionAll[2->1, id=60fa3495] from (2,944,662..3,277,827, 95.00%) to (2,944,662..3,277,827, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of out@SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] from (2,944,662..3,277,827, 95.00%) to (2,944,662..3,277,827, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in0@Alternative[3x ~Alternative[[UnionAll[2->1, id=3b220bcb]]], 53e211ee] from (2,944,662..3,277,827, 95.00%) to (2,944,662..3,277,827, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in0@UnionAll[2->1, id=3b220bcb] from (2,944,662..3,277,827, 95.00%) to (2,944,662..3,277,827, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in0@SparkUnionAll[2->1, id=2cf92cc7] from (2,944,662..3,277,827, 95.00%) to (2,944,662..3,277,827, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in0@JavaUnionAll[2->1, id=60fa3495] from (2,944,662..3,277,827, 95.00%) to (2,944,662..3,277,827, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of out@JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/lineitem.tbl] from (2,944,662..3,277,827, 95.00%) to (2,944,662..3,277,827, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in0@Alternative[3x ~Alternative[[UnionAll[2->1, id=3b220bcb]]], 53e211ee] from (2,944,662..3,277,827, 95.00%) to (2,944,662..3,277,827, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in0@UnionAll[2->1, id=3b220bcb] from (2,944,662..3,277,827, 95.00%) to (2,944,662..3,277,827, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in0@SparkUnionAll[2->1, id=2cf92cc7] from (2,944,662..3,277,827, 95.00%) to (2,944,662..3,277,827, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in0@JavaUnionAll[2->1, id=60fa3495] from (2,944,662..3,277,827, 95.00%) to (2,944,662..3,277,827, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of out@FlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] from null to (734,156..817,220, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in1@Alternative[3x ~Alternative[[UnionAll[2->1, id=3b220bcb]]], 53e211ee] from null to (734,156..817,220, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in1@UnionAll[2->1, id=3b220bcb] from null to (734,156..817,220, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in1@SparkUnionAll[2->1, id=2cf92cc7] from null to (734,156..817,220, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in1@JavaUnionAll[2->1, id=60fa3495] from null to (734,156..817,220, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of out@SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] from null to (734,156..817,220, 95.00%).
WARN main org.qcri.rheem.core.api.configuration.FunctionalKeyValueProvider - Creating fallback load estimator for FlatMapDescriptor[org.qcri.rheem.apps.sindy.Sindy$CellCreator@3a7704c].
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Setting time estimate of SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] to (0:00:00.236 .. 0:00:00.591, p=18.05%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in1@Alternative[3x ~Alternative[[UnionAll[2->1, id=3b220bcb]]], 53e211ee] from (734,156..817,220, 95.00%) to (734,156..817,220, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in1@UnionAll[2->1, id=3b220bcb] from (734,156..817,220, 95.00%) to (734,156..817,220, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in1@SparkUnionAll[2->1, id=2cf92cc7] from (734,156..817,220, 95.00%) to (734,156..817,220, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in1@JavaUnionAll[2->1, id=60fa3495] from (734,156..817,220, 95.00%) to (734,156..817,220, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of out@JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] from null to (734,156..817,220, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Setting time estimate of JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] to (0:00:00.245 .. 0:00:00.806, p=18.05%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in1@Alternative[3x ~Alternative[[UnionAll[2->1, id=3b220bcb]]], 53e211ee] from (734,156..817,220, 95.00%) to (734,156..817,220, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in1@UnionAll[2->1, id=3b220bcb] from (734,156..817,220, 95.00%) to (734,156..817,220, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in1@SparkUnionAll[2->1, id=2cf92cc7] from (734,156..817,220, 95.00%) to (734,156..817,220, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in1@JavaUnionAll[2->1, id=60fa3495] from (734,156..817,220, 95.00%) to (734,156..817,220, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of out@Alternative[3x ~Alternative[[FlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl]]], 4fe89c24] from null to (734,156..817,220, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in1@Alternative[3x ~Alternative[[UnionAll[2->1, id=3b220bcb]]], 53e211ee] from (734,156..817,220, 95.00%) to (734,156..817,220, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in1@UnionAll[2->1, id=3b220bcb] from (734,156..817,220, 95.00%) to (734,156..817,220, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in1@SparkUnionAll[2->1, id=2cf92cc7] from (734,156..817,220, 95.00%) to (734,156..817,220, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in1@JavaUnionAll[2->1, id=60fa3495] from (734,156..817,220, 95.00%) to (734,156..817,220, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of out@FlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] from (734,156..817,220, 95.00%) to (734,156..817,220, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in1@Alternative[3x ~Alternative[[UnionAll[2->1, id=3b220bcb]]], 53e211ee] from (734,156..817,220, 95.00%) to (734,156..817,220, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in1@UnionAll[2->1, id=3b220bcb] from (734,156..817,220, 95.00%) to (734,156..817,220, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in1@SparkUnionAll[2->1, id=2cf92cc7] from (734,156..817,220, 95.00%) to (734,156..817,220, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in1@JavaUnionAll[2->1, id=60fa3495] from (734,156..817,220, 95.00%) to (734,156..817,220, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of out@SparkFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] from (734,156..817,220, 95.00%) to (734,156..817,220, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in1@Alternative[3x ~Alternative[[UnionAll[2->1, id=3b220bcb]]], 53e211ee] from (734,156..817,220, 95.00%) to (734,156..817,220, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in1@UnionAll[2->1, id=3b220bcb] from (734,156..817,220, 95.00%) to (734,156..817,220, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in1@SparkUnionAll[2->1, id=2cf92cc7] from (734,156..817,220, 95.00%) to (734,156..817,220, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in1@JavaUnionAll[2->1, id=60fa3495] from (734,156..817,220, 95.00%) to (734,156..817,220, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of out@JavaFlatMap[my.udf.Sindy.flatmap1-Create cells for hdfs://thor01/data/csv/TPC-H/sf0_5/orders.tbl] from (734,156..817,220, 95.00%) to (734,156..817,220, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in1@Alternative[3x ~Alternative[[UnionAll[2->1, id=3b220bcb]]], 53e211ee] from (734,156..817,220, 95.00%) to (734,156..817,220, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in1@UnionAll[2->1, id=3b220bcb] from (734,156..817,220, 95.00%) to (734,156..817,220, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in1@SparkUnionAll[2->1, id=2cf92cc7] from (734,156..817,220, 95.00%) to (734,156..817,220, 95.00%).
DEBUG main org.qcri.rheem.core.optimizer.DefaultOptimizationContext - Changing cardinality of in1@JavaUnionAll[2->1, id=60fa3495] from (734,156..817,220, 95.00%) to (734,156..817,220, 95.00%).

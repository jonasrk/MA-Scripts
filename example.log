DEBUG main io.netty.util.NetUtil - Loopback interface: lo (lo, 0:0:0:0:0:0:0:1%lo)
DEBUG main io.netty.util.NetUtil - /proc/sys/net/core/somaxconn: 128
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
DEBUG main org.apache.hadoop.hdfs.DFSClient - No KeyProvider found.
DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@7283d3eb
DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@264f218
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Both short-circuit local reads and UNIX domain socket are disabled.
DEBUG main org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
DEBUG main org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
DEBUG main org.apache.hadoop.ipc.Client - Connecting to thor01/172.16.64.55:8020
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper: starting, having connections 1
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper sending #0
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper got value #0
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 97ms
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper sending #1
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper got value #1
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 1ms
DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@264f218
DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@264f218
DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@264f218
DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper: closed
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper: stopped, remaining connections 0
INFO main org.qcri.rheem.core.api.Configuration - Using configuration at file:/home/jonas.kemper/MA-Scripts/benchmark-thor-validation-July10-11uhr49.properties.
INFO main org.qcri.rheem.core.util.fs.HadoopFileSystem - Adding handler for HDFS URLs.
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Falling back to shell based
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: jonas.kemper
DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "UnixPrincipal: jonas.kemper" with name jonas.kemper
DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "jonas.kemper"
DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:jonas.kemper (auth:SIMPLE)
DEBUG main  - address: thor01/172.16.64.55 isLoopbackAddress: false, with host 172.16.64.55 thor01
DEBUG main io.netty.util.internal.logging.InternalLoggerFactory - Using SLF4J as the default logging framework
DEBUG main io.netty.util.internal.PlatformDependent0 - java.nio.Buffer.address: available
DEBUG main io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.theUnsafe: available
DEBUG main io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.copyMemory: available
DEBUG main io.netty.util.internal.PlatformDependent0 - java.nio.Bits.unaligned: true
DEBUG main io.netty.util.internal.PlatformDependent - Java version: 8
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.noUnsafe: false
DEBUG main io.netty.util.internal.PlatformDependent - sun.misc.Unsafe: available
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.noJavassist: false
DEBUG main io.netty.util.internal.PlatformDependent - Javassist: unavailable
DEBUG main io.netty.util.internal.PlatformDependent - You don't have Javassist in your class path or you don't have enough permission to load dynamically generated classes.  Please check the configuration for better performance.
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.tmpdir: /tmp (java.io.tmpdir)
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.bitMode: 64 (sun.arch.data.model)
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.noPreferDirect: false
DEBUG main io.netty.util.internal.NativeLibraryLoader - -Dio.netty.tmpdir: /tmp (java.io.tmpdir)
DEBUG main io.netty.util.internal.NativeLibraryLoader - -Dio.netty.netty.workdir: /tmp (io.netty.tmpdir)
DEBUG main io.netty.util.NetUtil - Loopback interface: lo (lo, 0:0:0:0:0:0:0:1%lo)
DEBUG main io.netty.util.NetUtil - /proc/sys/net/core/somaxconn: 128
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
DEBUG main org.apache.hadoop.hdfs.DFSClient - No KeyProvider found.
DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@7283d3eb
DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@264f218
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Both short-circuit local reads and UNIX domain socket are disabled.
DEBUG main org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
DEBUG main org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
DEBUG main org.apache.hadoop.ipc.Client - Connecting to thor01/172.16.64.55:8020
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper: starting, having connections 1
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper sending #0
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper got value #0
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 79ms
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper sending #1
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper got value #1
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 1ms
DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@264f218
DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@264f218
DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@264f218
DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper: closed
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper: stopped, remaining connections 0
INFO main org.qcri.rheem.core.api.Configuration - Using configuration at file:/home/jonas.kemper/MA-Scripts/benchmark-thor-validation-July10-11uhr49.properties.
INFO main org.qcri.rheem.core.util.fs.HadoopFileSystem - Adding handler for HDFS URLs.
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Falling back to shell based
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: jonas.kemper
DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "UnixPrincipal: jonas.kemper" with name jonas.kemper
DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "jonas.kemper"
DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:jonas.kemper (auth:SIMPLE)
DEBUG main  - address: thor01/172.16.64.55 isLoopbackAddress: false, with host 172.16.64.55 thor01
DEBUG main io.netty.util.internal.logging.InternalLoggerFactory - Using SLF4J as the default logging framework
DEBUG main io.netty.util.internal.PlatformDependent0 - java.nio.Buffer.address: available
DEBUG main io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.theUnsafe: available
DEBUG main io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.copyMemory: available
DEBUG main io.netty.util.internal.PlatformDependent0 - java.nio.Bits.unaligned: true
DEBUG main io.netty.util.internal.PlatformDependent - Java version: 8
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.noUnsafe: false
DEBUG main io.netty.util.internal.PlatformDependent - sun.misc.Unsafe: available
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.noJavassist: false
DEBUG main io.netty.util.internal.PlatformDependent - Javassist: unavailable
DEBUG main io.netty.util.internal.PlatformDependent - You don't have Javassist in your class path or you don't have enough permission to load dynamically generated classes.  Please check the configuration for better performance.
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.tmpdir: /tmp (java.io.tmpdir)
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.bitMode: 64 (sun.arch.data.model)
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.noPreferDirect: false
DEBUG main io.netty.util.internal.NativeLibraryLoader - -Dio.netty.tmpdir: /tmp (java.io.tmpdir)
DEBUG main io.netty.util.internal.NativeLibraryLoader - -Dio.netty.netty.workdir: /tmp (io.netty.tmpdir)
DEBUG main io.netty.util.NetUtil - Loopback interface: lo (lo, 0:0:0:0:0:0:0:1%lo)
DEBUG main io.netty.util.NetUtil - /proc/sys/net/core/somaxconn: 128
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
DEBUG main org.apache.hadoop.hdfs.DFSClient - No KeyProvider found.
DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@7283d3eb
DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@264f218
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Both short-circuit local reads and UNIX domain socket are disabled.
DEBUG main org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
DEBUG main org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
DEBUG main org.apache.hadoop.ipc.Client - Connecting to thor01/172.16.64.55:8020
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper: starting, having connections 1
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper sending #0
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper got value #0
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 86ms
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper sending #1
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper got value #1
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 1ms
DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@264f218
DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@264f218
DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@264f218
DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper: closed
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper: stopped, remaining connections 0
INFO main org.qcri.rheem.core.api.Configuration - Using configuration at file:/home/jonas.kemper/MA-Scripts/benchmark-thor-validation-July10-11uhr49.properties.
INFO main org.qcri.rheem.core.util.fs.HadoopFileSystem - Adding handler for HDFS URLs.
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Falling back to shell based
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: jonas.kemper
DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "UnixPrincipal: jonas.kemper" with name jonas.kemper
DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "jonas.kemper"
DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:jonas.kemper (auth:SIMPLE)
DEBUG main  - address: thor01/172.16.64.55 isLoopbackAddress: false, with host 172.16.64.55 thor01
DEBUG main io.netty.util.internal.logging.InternalLoggerFactory - Using SLF4J as the default logging framework
DEBUG main io.netty.util.internal.PlatformDependent0 - java.nio.Buffer.address: available
DEBUG main io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.theUnsafe: available
DEBUG main io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.copyMemory: available
DEBUG main io.netty.util.internal.PlatformDependent0 - java.nio.Bits.unaligned: true
DEBUG main io.netty.util.internal.PlatformDependent - Java version: 8
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.noUnsafe: false
DEBUG main io.netty.util.internal.PlatformDependent - sun.misc.Unsafe: available
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.noJavassist: false
DEBUG main io.netty.util.internal.PlatformDependent - Javassist: unavailable
DEBUG main io.netty.util.internal.PlatformDependent - You don't have Javassist in your class path or you don't have enough permission to load dynamically generated classes.  Please check the configuration for better performance.
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.tmpdir: /tmp (java.io.tmpdir)
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.bitMode: 64 (sun.arch.data.model)
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.noPreferDirect: false
DEBUG main io.netty.util.internal.NativeLibraryLoader - -Dio.netty.tmpdir: /tmp (java.io.tmpdir)
DEBUG main io.netty.util.internal.NativeLibraryLoader - -Dio.netty.netty.workdir: /tmp (io.netty.tmpdir)
DEBUG main io.netty.util.NetUtil - Loopback interface: lo (lo, 0:0:0:0:0:0:0:1%lo)
DEBUG main io.netty.util.NetUtil - /proc/sys/net/core/somaxconn: 128
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
DEBUG main org.apache.hadoop.hdfs.DFSClient - No KeyProvider found.
DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@7283d3eb
DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@264f218
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Both short-circuit local reads and UNIX domain socket are disabled.
DEBUG main org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
DEBUG main org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
DEBUG main org.apache.hadoop.ipc.Client - Connecting to thor01/172.16.64.55:8020
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper: starting, having connections 1
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper sending #0
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper got value #0
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 80ms
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper sending #1
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper got value #1
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 1ms
DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@264f218
DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@264f218
DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@264f218
DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper: closed
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper: stopped, remaining connections 0
INFO main org.qcri.rheem.core.api.Configuration - Using configuration at file:/home/jonas.kemper/MA-Scripts/benchmark-thor-validation-July10-11uhr49.properties.
INFO main org.qcri.rheem.core.util.fs.HadoopFileSystem - Adding handler for HDFS URLs.
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Falling back to shell based
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: jonas.kemper
DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "UnixPrincipal: jonas.kemper" with name jonas.kemper
DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "jonas.kemper"
DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:jonas.kemper (auth:SIMPLE)
DEBUG main  - address: thor01/172.16.64.55 isLoopbackAddress: false, with host 172.16.64.55 thor01
DEBUG main io.netty.util.internal.logging.InternalLoggerFactory - Using SLF4J as the default logging framework
DEBUG main io.netty.util.internal.PlatformDependent0 - java.nio.Buffer.address: available
DEBUG main io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.theUnsafe: available
DEBUG main io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.copyMemory: available
DEBUG main io.netty.util.internal.PlatformDependent0 - java.nio.Bits.unaligned: true
DEBUG main io.netty.util.internal.PlatformDependent - Java version: 8
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.noUnsafe: false
DEBUG main io.netty.util.internal.PlatformDependent - sun.misc.Unsafe: available
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.noJavassist: false
DEBUG main io.netty.util.internal.PlatformDependent - Javassist: unavailable
DEBUG main io.netty.util.internal.PlatformDependent - You don't have Javassist in your class path or you don't have enough permission to load dynamically generated classes.  Please check the configuration for better performance.
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.tmpdir: /tmp (java.io.tmpdir)
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.bitMode: 64 (sun.arch.data.model)
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.noPreferDirect: false
DEBUG main io.netty.util.internal.NativeLibraryLoader - -Dio.netty.tmpdir: /tmp (java.io.tmpdir)
DEBUG main io.netty.util.internal.NativeLibraryLoader - -Dio.netty.netty.workdir: /tmp (io.netty.tmpdir)
DEBUG main io.netty.util.NetUtil - Loopback interface: lo (lo, 0:0:0:0:0:0:0:1%lo)
DEBUG main io.netty.util.NetUtil - /proc/sys/net/core/somaxconn: 128
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
DEBUG main org.apache.hadoop.hdfs.DFSClient - No KeyProvider found.
DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@7283d3eb
DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@264f218
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Both short-circuit local reads and UNIX domain socket are disabled.
DEBUG main org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
DEBUG main org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
DEBUG main org.apache.hadoop.ipc.Client - Connecting to thor01/172.16.64.55:8020
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper: starting, having connections 1
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper sending #0
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper got value #0
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 83ms
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper sending #1
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper got value #1
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 2ms
DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@264f218
DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@264f218
DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@264f218
DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper: closed
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper: stopped, remaining connections 0
INFO main org.qcri.rheem.core.api.Configuration - Using configuration at file:/home/jonas.kemper/MA-Scripts/benchmark-thor-validation-July10-11uhr49.properties.
INFO main org.qcri.rheem.core.util.fs.HadoopFileSystem - Adding handler for HDFS URLs.
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Falling back to shell based
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: jonas.kemper
DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "UnixPrincipal: jonas.kemper" with name jonas.kemper
DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "jonas.kemper"
DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:jonas.kemper (auth:SIMPLE)
DEBUG main  - address: thor01/172.16.64.55 isLoopbackAddress: false, with host 172.16.64.55 thor01
DEBUG main io.netty.util.internal.logging.InternalLoggerFactory - Using SLF4J as the default logging framework
DEBUG main io.netty.util.internal.PlatformDependent0 - java.nio.Buffer.address: available
DEBUG main io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.theUnsafe: available
DEBUG main io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.copyMemory: available
DEBUG main io.netty.util.internal.PlatformDependent0 - java.nio.Bits.unaligned: true
DEBUG main io.netty.util.internal.PlatformDependent - Java version: 8
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.noUnsafe: false
DEBUG main io.netty.util.internal.PlatformDependent - sun.misc.Unsafe: available
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.noJavassist: false
DEBUG main io.netty.util.internal.PlatformDependent - Javassist: unavailable
DEBUG main io.netty.util.internal.PlatformDependent - You don't have Javassist in your class path or you don't have enough permission to load dynamically generated classes.  Please check the configuration for better performance.
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.tmpdir: /tmp (java.io.tmpdir)
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.bitMode: 64 (sun.arch.data.model)
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.noPreferDirect: false
DEBUG main io.netty.util.internal.NativeLibraryLoader - -Dio.netty.tmpdir: /tmp (java.io.tmpdir)
DEBUG main io.netty.util.internal.NativeLibraryLoader - -Dio.netty.netty.workdir: /tmp (io.netty.tmpdir)
DEBUG main io.netty.util.NetUtil - Loopback interface: lo (lo, 0:0:0:0:0:0:0:1%lo)
DEBUG main io.netty.util.NetUtil - /proc/sys/net/core/somaxconn: 128
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
DEBUG main org.apache.hadoop.hdfs.DFSClient - No KeyProvider found.
DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@7283d3eb
DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@264f218
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Both short-circuit local reads and UNIX domain socket are disabled.
DEBUG main org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
DEBUG main org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
DEBUG main org.apache.hadoop.ipc.Client - Connecting to thor01/172.16.64.55:8020
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper: starting, having connections 1
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper sending #0
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper got value #0
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 78ms
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper sending #1
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper got value #1
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 1ms
DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@264f218
DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@264f218
DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@264f218
DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper: closed
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper: stopped, remaining connections 0
INFO main org.qcri.rheem.core.api.Configuration - Using configuration at file:/home/jonas.kemper/MA-Scripts/benchmark-thor-validation-July10-11uhr49.properties.
INFO main org.qcri.rheem.core.util.fs.HadoopFileSystem - Adding handler for HDFS URLs.
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Falling back to shell based
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: jonas.kemper
DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "UnixPrincipal: jonas.kemper" with name jonas.kemper
DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "jonas.kemper"
DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:jonas.kemper (auth:SIMPLE)
DEBUG main  - address: thor01/172.16.64.55 isLoopbackAddress: false, with host 172.16.64.55 thor01
DEBUG main io.netty.util.internal.logging.InternalLoggerFactory - Using SLF4J as the default logging framework
DEBUG main io.netty.util.internal.PlatformDependent0 - java.nio.Buffer.address: available
DEBUG main io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.theUnsafe: available
DEBUG main io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.copyMemory: available
DEBUG main io.netty.util.internal.PlatformDependent0 - java.nio.Bits.unaligned: true
DEBUG main io.netty.util.internal.PlatformDependent - Java version: 8
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.noUnsafe: false
DEBUG main io.netty.util.internal.PlatformDependent - sun.misc.Unsafe: available
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.noJavassist: false
DEBUG main io.netty.util.internal.PlatformDependent - Javassist: unavailable
DEBUG main io.netty.util.internal.PlatformDependent - You don't have Javassist in your class path or you don't have enough permission to load dynamically generated classes.  Please check the configuration for better performance.
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.tmpdir: /tmp (java.io.tmpdir)
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.bitMode: 64 (sun.arch.data.model)
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.noPreferDirect: false
DEBUG main io.netty.util.internal.NativeLibraryLoader - -Dio.netty.tmpdir: /tmp (java.io.tmpdir)
DEBUG main io.netty.util.internal.NativeLibraryLoader - -Dio.netty.netty.workdir: /tmp (io.netty.tmpdir)
DEBUG main io.netty.util.NetUtil - Loopback interface: lo (lo, 0:0:0:0:0:0:0:1%lo)
DEBUG main io.netty.util.NetUtil - /proc/sys/net/core/somaxconn: 128
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
DEBUG main org.apache.hadoop.hdfs.DFSClient - No KeyProvider found.
DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@7283d3eb
DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@264f218
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Both short-circuit local reads and UNIX domain socket are disabled.
DEBUG main org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
DEBUG main org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
DEBUG main org.apache.hadoop.ipc.Client - Connecting to thor01/172.16.64.55:8020
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper: starting, having connections 1
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper sending #0
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper got value #0
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 82ms
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper sending #1
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper got value #1
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 1ms
DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@264f218
DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@264f218
DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@264f218
DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper: closed
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper: stopped, remaining connections 0
INFO main org.qcri.rheem.core.api.Configuration - Using configuration at file:/home/jonas.kemper/MA-Scripts/benchmark-thor-validation-July10-11uhr49.properties.
INFO main org.qcri.rheem.core.util.fs.HadoopFileSystem - Adding handler for HDFS URLs.
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Falling back to shell based
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: jonas.kemper
DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "UnixPrincipal: jonas.kemper" with name jonas.kemper
DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "jonas.kemper"
DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:jonas.kemper (auth:SIMPLE)
DEBUG main  - address: thor01/172.16.64.55 isLoopbackAddress: false, with host 172.16.64.55 thor01
DEBUG main io.netty.util.internal.logging.InternalLoggerFactory - Using SLF4J as the default logging framework
DEBUG main io.netty.util.internal.PlatformDependent0 - java.nio.Buffer.address: available
DEBUG main io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.theUnsafe: available
DEBUG main io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.copyMemory: available
DEBUG main io.netty.util.internal.PlatformDependent0 - java.nio.Bits.unaligned: true
DEBUG main io.netty.util.internal.PlatformDependent - Java version: 8
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.noUnsafe: false
DEBUG main io.netty.util.internal.PlatformDependent - sun.misc.Unsafe: available
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.noJavassist: false
DEBUG main io.netty.util.internal.PlatformDependent - Javassist: unavailable
DEBUG main io.netty.util.internal.PlatformDependent - You don't have Javassist in your class path or you don't have enough permission to load dynamically generated classes.  Please check the configuration for better performance.
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.tmpdir: /tmp (java.io.tmpdir)
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.bitMode: 64 (sun.arch.data.model)
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.noPreferDirect: false
DEBUG main io.netty.util.internal.NativeLibraryLoader - -Dio.netty.tmpdir: /tmp (java.io.tmpdir)
DEBUG main io.netty.util.internal.NativeLibraryLoader - -Dio.netty.netty.workdir: /tmp (io.netty.tmpdir)
DEBUG main io.netty.util.NetUtil - Loopback interface: lo (lo, 0:0:0:0:0:0:0:1%lo)
DEBUG main io.netty.util.NetUtil - /proc/sys/net/core/somaxconn: 128
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
DEBUG main org.apache.hadoop.hdfs.DFSClient - No KeyProvider found.
DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@7283d3eb
DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@264f218
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Both short-circuit local reads and UNIX domain socket are disabled.
DEBUG main org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
DEBUG main org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
DEBUG main org.apache.hadoop.ipc.Client - Connecting to thor01/172.16.64.55:8020
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper: starting, having connections 1
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper sending #0
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper got value #0
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 81ms
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper sending #1
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper got value #1
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 1ms
DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@264f218
DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@264f218
DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@264f218
DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper: closed
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper: stopped, remaining connections 0
INFO main org.qcri.rheem.core.api.Configuration - Using configuration at file:/home/jonas.kemper/MA-Scripts/benchmark-thor-validation-July10-11uhr49.properties.
INFO main org.qcri.rheem.core.util.fs.HadoopFileSystem - Adding handler for HDFS URLs.
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Falling back to shell based
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: jonas.kemper
DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "UnixPrincipal: jonas.kemper" with name jonas.kemper
DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "jonas.kemper"
DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:jonas.kemper (auth:SIMPLE)
DEBUG main  - address: thor01/172.16.64.55 isLoopbackAddress: false, with host 172.16.64.55 thor01
DEBUG main io.netty.util.internal.logging.InternalLoggerFactory - Using SLF4J as the default logging framework
DEBUG main io.netty.util.internal.PlatformDependent0 - java.nio.Buffer.address: available
DEBUG main io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.theUnsafe: available
DEBUG main io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.copyMemory: available
DEBUG main io.netty.util.internal.PlatformDependent0 - java.nio.Bits.unaligned: true
DEBUG main io.netty.util.internal.PlatformDependent - Java version: 8
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.noUnsafe: false
DEBUG main io.netty.util.internal.PlatformDependent - sun.misc.Unsafe: available
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.noJavassist: false
DEBUG main io.netty.util.internal.PlatformDependent - Javassist: unavailable
DEBUG main io.netty.util.internal.PlatformDependent - You don't have Javassist in your class path or you don't have enough permission to load dynamically generated classes.  Please check the configuration for better performance.
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.tmpdir: /tmp (java.io.tmpdir)
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.bitMode: 64 (sun.arch.data.model)
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.noPreferDirect: false
DEBUG main io.netty.util.internal.NativeLibraryLoader - -Dio.netty.tmpdir: /tmp (java.io.tmpdir)
DEBUG main io.netty.util.internal.NativeLibraryLoader - -Dio.netty.netty.workdir: /tmp (io.netty.tmpdir)
DEBUG main io.netty.util.NetUtil - Loopback interface: lo (lo, 0:0:0:0:0:0:0:1%lo)
DEBUG main io.netty.util.NetUtil - /proc/sys/net/core/somaxconn: 128
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
DEBUG main org.apache.hadoop.hdfs.DFSClient - No KeyProvider found.
DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@7283d3eb
DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@264f218
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Both short-circuit local reads and UNIX domain socket are disabled.
DEBUG main org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
DEBUG main org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
DEBUG main org.apache.hadoop.ipc.Client - Connecting to thor01/172.16.64.55:8020
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper: starting, having connections 1
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper sending #0
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper got value #0
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 95ms
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper sending #1
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper got value #1
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 1ms
DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@264f218
DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@264f218
DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@264f218
DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper: closed
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper: stopped, remaining connections 0
INFO main org.qcri.rheem.core.api.Configuration - Using configuration at file:/home/jonas.kemper/MA-Scripts/benchmark-thor-validation-July10-11uhr49.properties.
INFO main org.qcri.rheem.core.util.fs.HadoopFileSystem - Adding handler for HDFS URLs.
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Falling back to shell based
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: jonas.kemper
DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "UnixPrincipal: jonas.kemper" with name jonas.kemper
DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "jonas.kemper"
DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:jonas.kemper (auth:SIMPLE)
DEBUG main  - address: thor01/172.16.64.55 isLoopbackAddress: false, with host 172.16.64.55 thor01
DEBUG main io.netty.util.internal.logging.InternalLoggerFactory - Using SLF4J as the default logging framework
DEBUG main io.netty.util.internal.PlatformDependent0 - java.nio.Buffer.address: available
DEBUG main io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.theUnsafe: available
DEBUG main io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.copyMemory: available
DEBUG main io.netty.util.internal.PlatformDependent0 - java.nio.Bits.unaligned: true
DEBUG main io.netty.util.internal.PlatformDependent - Java version: 8
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.noUnsafe: false
DEBUG main io.netty.util.internal.PlatformDependent - sun.misc.Unsafe: available
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.noJavassist: false
DEBUG main io.netty.util.internal.PlatformDependent - Javassist: unavailable
DEBUG main io.netty.util.internal.PlatformDependent - You don't have Javassist in your class path or you don't have enough permission to load dynamically generated classes.  Please check the configuration for better performance.
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.tmpdir: /tmp (java.io.tmpdir)
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.bitMode: 64 (sun.arch.data.model)
DEBUG main io.netty.util.internal.PlatformDependent - -Dio.netty.noPreferDirect: false
DEBUG main io.netty.util.internal.NativeLibraryLoader - -Dio.netty.tmpdir: /tmp (java.io.tmpdir)
DEBUG main io.netty.util.internal.NativeLibraryLoader - -Dio.netty.netty.workdir: /tmp (io.netty.tmpdir)
DEBUG main io.netty.util.NetUtil - Loopback interface: lo (lo, 0:0:0:0:0:0:0:1%lo)
DEBUG main io.netty.util.NetUtil - /proc/sys/net/core/somaxconn: 128
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
DEBUG main org.apache.hadoop.hdfs.DFSClient - No KeyProvider found.
DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@7283d3eb
DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@264f218
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Both short-circuit local reads and UNIX domain socket are disabled.
DEBUG main org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
DEBUG main org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
DEBUG main org.apache.hadoop.ipc.Client - Connecting to thor01/172.16.64.55:8020
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper: starting, having connections 1
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper sending #0
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper got value #0
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 86ms
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper sending #1
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper got value #1
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 1ms
DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@264f218
DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@264f218
DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@264f218
DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper: closed
DEBUG IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper org.apache.hadoop.ipc.Client - IPC Client (2032169857) connection to thor01/172.16.64.55:8020 from jonas.kemper: stopped, remaining connections 0
INFO main org.qcri.rheem.core.api.Configuration - Using configuration at file:/home/jonas.kemper/MA-Scripts/benchmark-thor-validation-July10-11uhr49.properties.
WARN main org.qcri.rheem.core.optimizer.costs.LoadProfileEstimators - Could not find an selectivity specification associated with 'Configuration[file:/home/jonas.kemper/MA-Scripts/benchmark-thor-validation-July10-11uhr49.properties]'.
INFO main org.qcri.rheem.core.api.Configuration - Using configuration at file:/home/jonas.kemper/MA-Scripts/benchmark-thor-validation-July10-11uhr49.properties.
WARN main org.qcri.rheem.core.optimizer.costs.LoadProfileEstimators - Could not find an selectivity specification associated with 'Configuration[file:/home/jonas.kemper/MA-Scripts/benchmark-thor-validation-July10-11uhr49.properties]'.
INFO main org.qcri.rheem.core.api.Configuration - Using configuration at file:/home/jonas.kemper/MA-Scripts/benchmark-thor-validation-July10-11uhr49.properties.
WARN main org.qcri.rheem.core.optimizer.costs.LoadProfileEstimators - Could not find an selectivity specification associated with 'Configuration[file:/home/jonas.kemper/MA-Scripts/benchmark-thor-validation-July10-11uhr49.properties]'.
INFO main org.qcri.rheem.core.api.Configuration - Using configuration at file:/home/jonas.kemper/MA-Scripts/benchmark-thor-validation-July10-11uhr49.properties.
WARN main org.qcri.rheem.core.optimizer.costs.LoadProfileEstimators - Could not find an selectivity specification associated with 'Configuration[file:/home/jonas.kemper/MA-Scripts/benchmark-thor-validation-July10-11uhr49.properties]'.
INFO main org.qcri.rheem.core.api.Configuration - Using configuration at file:/home/jonas.kemper/MA-Scripts/benchmark-thor-validation-July10-11uhr49.properties.
WARN main org.qcri.rheem.core.optimizer.costs.LoadProfileEstimators - Could not find an selectivity specification associated with 'Configuration[file:/home/jonas.kemper/MA-Scripts/benchmark-thor-validation-July10-11uhr49.properties]'.
INFO main org.qcri.rheem.core.api.Configuration - Using configuration at file:/home/jonas.kemper/MA-Scripts/benchmark-thor-validation-July10-11uhr49.properties.
WARN main org.qcri.rheem.core.optimizer.costs.LoadProfileEstimators - Could not find an selectivity specification associated with 'Configuration[file:/home/jonas.kemper/MA-Scripts/benchmark-thor-validation-July10-11uhr49.properties]'.
INFO main org.qcri.rheem.core.api.Configuration - Using configuration at file:/home/jonas.kemper/MA-Scripts/benchmark-thor-validation-July10-11uhr49.properties.
WARN main org.qcri.rheem.core.optimizer.costs.LoadProfileEstimators - Could not find an selectivity specification associated with 'Configuration[file:/home/jonas.kemper/MA-Scripts/benchmark-thor-validation-July10-11uhr49.properties]'.
